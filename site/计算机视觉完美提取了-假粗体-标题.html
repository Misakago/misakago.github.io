<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Untitled - Misaka's Tech Blog</title>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            line-height: 1.6;
            color: #333;
            background: #f5f5f5;
        }
        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 20px;
        }
        header {
            background: #2c3e50;
            color: white;
            padding: 2rem 0;
            margin-bottom: 2rem;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        header h1 { margin: 0; font-size: 2rem; }
        header p { opacity: 0.8; margin-top: 0.5rem; }
        nav {
            background: #34495e;
            padding: 1rem 0;
            position: sticky;
            top: 0;
            z-index: 100;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        nav a {
            color: #ecf0f1;
            text-decoration: none;
            padding: 0.5rem 1rem;
            margin: 0 0.5rem;
            border-radius: 4px;
            transition: background 0.3s;
        }
        nav a:hover { background: #1abc9c; }
        .article {
            background: white;
            padding: 2rem;
            border-radius: 8px;
            box-shadow: 0 2px 8px rgba(0,0,0,0.1);
            margin-bottom: 2rem;
        }
        .article h1 { color: #2c3e50; margin-bottom: 1rem; font-size: 2rem; }
        .article h2 { color: #34495e; margin: 2rem 0 1rem; font-size: 1.5rem; border-bottom: 2px solid #ecf0f1; padding-bottom: 0.5rem; }
        .article h3 { color: #7f8c8d; margin: 1.5rem 0 0.5rem; font-size: 1.3rem; }
        .article h4 { color: #95a5a6; margin: 1rem 0 0.5rem; font-size: 1.1rem; }
        .article p { margin-bottom: 1rem; text-align: justify; }
        .article ul, .article ol { margin-left: 2rem; margin-bottom: 1rem; }
        .article li { margin-bottom: 0.5rem; }
        .article code {
            background: #f8f9fa;
            padding: 0.2rem 0.4rem;
            border-radius: 3px;
            font-family: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;
            font-size: 0.9em;
        }
        .article pre {
            background: #2c3e50;
            color: #ecf0f1;
            padding: 1.5rem;
            border-radius: 6px;
            overflow-x: auto;
            margin-bottom: 1.5rem;
        }
        .article pre code {
            background: transparent;
            padding: 0;
            color: inherit;
        }
        .article blockquote {
            border-left: 4px solid #3498db;
            padding-left: 1.5rem;
            margin: 1.5rem 0;
            color: #7f8c8d;
            font-style: italic;
        }
        .article table {
            width: 100%;
            border-collapse: collapse;
            margin: 1.5rem 0;
        }
        .article table th, .article table td {
            border: 1px solid #ddd;
            padding: 0.75rem;
            text-align: left;
        }
        .article table th { background: #34495e; color: white; }
        .article table tr:nth-child(even) { background: #f8f9fa; }
        .article img {
            max-width: 100%;
            height: auto;
            border-radius: 4px;
            margin: 1.5rem 0;
            box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        }
        .article a { color: #3498db; text-decoration: none; }
        .article a:hover { text-decoration: underline; }
        .meta {
            color: #7f8c8d;
            font-size: 0.9rem;
            margin-bottom: 2rem;
            padding-bottom: 1rem;
            border-bottom: 1px solid #ecf0f1;
        }
        .index-item {
            background: white;
            padding: 1.5rem;
            border-radius: 8px;
            margin-bottom: 1rem;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
            transition: transform 0.3s, box-shadow 0.3s;
        }
        .index-item:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0,0,0,0.15);
        }
        .index-item h2 { margin-bottom: 0.5rem; }
        .index-item h2 a { color: #2c3e50; text-decoration: none; }
        .index-item h2 a:hover { color: #3498db; }
        .index-item p { color: #7f8c8d; }
        .index-date { color: #95a5a6; font-size: 0.9rem; }
        footer {
            text-align: center;
            padding: 2rem;
            color: #7f8c8d;
            margin-top: 3rem;
        }
        footer a { color: #3498db; text-decoration: none; }
        .back-link { display: inline-block; margin-bottom: 1rem; color: #3498db; text-decoration: none; }
        .tag { display: inline-block; background: #ecf0f1; padding: 0.25rem 0.75rem; border-radius: 20px; font-size: 0.85rem; margin-right: 0.5rem; }
        @media (max-width: 768px) {
            .container { padding: 10px; }
            .article { padding: 1.5rem; }
            header h1 { font-size: 1.5rem; }
        }
    </style>
</head>
<body>
    <header>
        <div class="container">
            <h1>Misaka's Tech Blog</h1>
            <p>技术分享与实践记录</p>
        </div>
    </header>
    <nav>
        <div class="container">
            <a href="https://misakago.github.io/">首页</a>
            <a href="https://github.com/Misakago" target="_blank">GitHub</a>
        </div>
    </nav>
    <div class="container">
        
        <a href="/" class="back-link">← 返回首页</a>
        <article class="article">
            <h1>Untitled</h1>
            <div class="meta">发布于 2026-02-09</div>
            <ol>
<li># 计算机视觉完美提取了“假粗体”标题</li>
</ol>
<br>
<ol>
<li>### 问题背景：一只“看不见”的拦路虎</li>
</ol>
<br>
<p>最近接到一个看似简单的需求文档完整性校验：<strong>从一份 PDF 文档中自动提取所有章节标题。</strong></p>
<br>
<p>按照以往的经验，这属于常规操作。通常 PDF 中的标题会有特定的层级标签，或者字体会有明显的 <code>Bold</code>（加粗）属性。然而，在处理这份特定的中文文档时，我们撞上了一堵墙：</p>
<br>
<ul>
<li><strong>视觉上：</strong> 标题明明比正文粗，肉眼区分一目了然。</li>
<li><strong>数据上：</strong> 标题和正文使用的是<strong>完全相同</strong>的字体文件，字号也完全一致。</li>
<li><strong>元数据：</strong> 使用 <code>PyMuPDF</code> (fitz) 查看，字体的 <code>flags</code> 并没有 <code>bold</code> 属性。</li>
</ol>
<br>
<p>这是一种典型的“假粗体”（Fake Bold）<strong>。生成 PDF 的软件（如 Word 或某些排版引擎）为了模拟粗体效果，并没有切换字重，而是通过</strong>多次微移重印<strong>或</strong>描边渲染来实现变粗。</p>
<br>
<p>这就导致了一个无解的局面：<strong>在代码眼里，标题和正文是孪生兄弟，完全无法区分。</strong></p>
<br>
<ol>
<li>### 那些走不通的弯路</li>
</ol>
<br>
<p>为了解决这个问题，我们尝试了几乎所有常规和非常规手段，但都铩羽而归：</p>
<br>
<ol>
<li><strong>OCR</strong> <strong>+</strong> <strong>LLM</strong><strong>（</strong><strong>大模型</strong><strong>）：</strong> 将页面转图，用 OCR 识别文字，再丢给 LLM 提取。</li>
</ol>
<p>1. <em>失败原因：</em> 速度极慢，且 LLM 经常“幻觉”，对于层级结构的还原很不稳定，成本也高。</p>
<ol>
<li><strong>PDF 转 Word/</strong><strong>HTML</strong><strong>：</strong> 寄希望于转换工具能识别粗体。</li>
</ol>
<p>1. <em>失败原因：</em> 转换后的文档同样丢失了 <code><b></code> 标签，样式变成了一堆乱七八糟的 <code>span</code>，毫无规律。</p>
<ol>
<li><strong>字号分析：</strong></li>
</ol>
<p>1. <em>失败原因：</em> 绝望地发现，这份文档的各级标题和正文竟然是<strong>一样大的</strong>。</p>
<ol>
<li><strong>黑度占比（</strong><strong>Pixel</strong> <strong>Density）：</strong> 计算文字区域黑色像素的百分比。</li>
</ol>
<p>1. <em>失败原因：</em> 复杂的汉字（如“繁”）天生就比简单的汉字（如“一”）黑度高。这会导致笔画多的正文被误判为标题。</p>
<br>
<ol>
<li>### 破局思路：像人眼一样“看”文档</li>
</ol>
<br>
<p>既然元数据在撒谎，那就回到最原始的逻辑：<strong>为什么人眼能一眼看出它是标题？</strong></p>
<br>
<p>因为<strong>笔画变粗了</strong>。</p>
<br>
<p>无论汉字结构多么复杂，只要它是粗体，其<strong>笔画的物理宽度</strong>（Stroke Width）一定大于细体。我们们需要一个算法，能够忽略汉字的复杂结构，直接度量“笔画的厚度”。</p>
<br>
<p><strong>解决方案：PyMuPDF（用于操作 PDF） + OpenCV（用于视觉分析） + K-Means（用于</strong><strong>聚类</strong><strong>判定）。</strong></p>
<br>
<ol>
<li>### 核心技术原理与演进</li>
</ol>
<br>
<h4>4.1 核心算法：距离变换（Distance Transform）</h4>
<br>
<p>直接计算黑色像素占比行不通，我们们采用 <code>cv2.distanceTransform</code>。 这个算法计算图像中<strong>每个前景像素（白色）到最近背景像素（黑色）的距离</strong>。</p>
<br>
<ul>
<li>在笔画的边缘，距离接近 0。</li>
<li>在笔画的中心线（骨架），距离最大。</li>
<li><strong>这个最大的距离值，就约等于笔画半径。</strong></li>
</ol>
<br>
<p>通过计算一个汉字区域内所有像素的距离平均值，我们们就能得到一个不受汉字结构影响的“<strong>视觉粗细分（Thickness Score）</strong>”。</p>
<br>
<h4>4.2 难点一：标点符号与英文的干扰</h4>
<br>
<p>一开始，我们直接对整行文字进行分析，结果惨不忍睹。</p>
<br>
<ul>
<li>英文单词的笔画逻辑与中文不同。</li>
<li><strong>标点符号（如逗号、分号）是极其密集的色块</strong>。一个极小的 <code>.</code> 或 <code>；</code> 在二值化后密度极高，会瞬间拉高整行的“粗细分”，导致正文里的短句被误判为标题。</li>
</ol>
<br>
<p><strong>对策：只看汉字（在此案例中，标题一定是中文）。</strong> 利用正则 <code>[\u4e00-\u9fff]</code> 过滤，只有汉字才参与计算。</p>
<br>
<h4>4.3 难点二：物理粘连（The "Redaction" Trick）</h4>
<br>
<p>虽然我们在代码逻辑上过滤了标点，但在 OpenCV 切割图片（ROI）时，如果一个逗号紧挨着汉字，切割出来的矩形框里难免会带入逗号的黑色像素，依然会干扰计算。</p>
<br>
<p><strong>终极杀招：物理擦除（Redaction）。</strong></p>
<br>
<p>既然标点碍事，我们就在渲染图片给 OpenCV 之前，<strong>直接在 PDF 层面把非汉字内容“涂白”</strong>。</p>
<br>
<ol>
<li>利用 PyMuPDF 获取所有非汉字字符的坐标。</li>
<li>使用 <code>page.add_redact_annot()</code> 对这些区域添加白色遮罩。</li>
<li><code>page.apply_redactions()</code> 应用擦除。</li>
<li><strong>渲染出一张只有汉字悬浮在空中的“纯净图片”。</strong></li>
</ol>
<br>
<p>这样，OpenCV 看到的只有纯粹的汉字，准确率瞬间提升至 99%。</p>
<br>
<h4>4.4 难点三：无监督聚类</h4>
<br>
<p>不同扫描件的分辨率不同，我们们不能硬编码 <code>score > 1.5</code> 这种阈值。 我们使用了 <strong>K-Means</strong> <strong>聚类算法</strong>。将全书所有行的粗细分丢进去，让算法自动分成“粗体组”和“细体组”。即使正文是 0.8，标题是 1.2，算法也能精准切分。</p>
<br>
<h4>4.5 难点四：丢失的序号（Corner Case）</h4>
<br>
<p>由于我们们“擦除”了数字，提取出来的标题变成了 <code>" 目的与范围"</code>，原本的 <code>"1 目的与范围"</code> 中的 <code>"1"</code> 丢失了。或者有时候序号和标题在 PDF 结构里甚至是分行的。</p>
<br>
<p><strong>对策：空间回溯（Spatial Recovery）。</strong> 确定某行汉字是标题后，利用它的坐标（BBox），去原始文档（未擦除版）中查找“位于该行左侧”<strong>且</strong>“高度对齐”的字符，将其召回并拼接。</p>
<br>
<ol>
<li>### 最终代码实现（精华版）</li>
</ol>
<br>
<p>这是集成了上述所有智慧的最终逻辑摘要：</p>
<br>
<pre><code class="language-Python">import fitz  # PyMuPDFimport cv2
import numpy as np
from sklearn.cluster import KMeans
import re

def analyze_pdf_titles(pdf_path):# 双句柄模式：doc用于擦除渲染，doc_orig用于回溯文本
    doc = fitz.open(pdf_path)
    doc_orig = fitz.open(pdf_path)
    
    all_lines = []

    for page_num, page in enumerate(doc):
        # 1. 【物理擦除】准备工作：找出所有非汉字
        text_dict = page.get_text("rawdict")
        redact_list = []
        for block in text_dict["blocks"]:
            for line in block["lines"]:
                for span in line["spans"]:
                    for char in span["chars"]:
                        # 如果不是汉字 (U+4E00 ~ U+9FFF)if not ('\u4e00' &lt;= char["c"] &lt;= '\u9fff'):
                            redact_list.append(char["bbox"])

        # 2. 【物理擦除】执行：将非汉字涂成白色for bbox in redact_list:
            page.add_redact_annot(bbox, fill=(1, 1, 1))
        page.apply_redactions()

        # 3. 【视觉分析】渲染高清图 -&gt; 转灰度 -&gt; 二值化
        pix = page.get_pixmap(matrix=fitz.Matrix(3, 3), alpha=False)
        img = np.frombuffer(pix.samples, dtype=np.uint8).reshape(pix.h, pix.w, 3)
        img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        # 反转：文字变白，背景变黑
        _, img_bin = cv2.threshold(img_gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)

        # 4. 【计算粗细】针对剩下的纯汉字计算距离变换# ... (遍历 text_dict 计算每个汉字的 stroke width) ...# 核心算法：# dist = cv2.distanceTransform(roi, cv2.DIST_L2, 3)# thickness = np.mean(dist[roi &gt; 0])# 收集每行的 thickness_score# 5. 【聚类判定】K-Means 自动区分粗细
    scores = np.array([x['score'] for x in all_lines]).reshape(-1, 1)
    kmeans = KMeans(n_clusters=2).fit(scores)
    bold_label = np.argmax(kmeans.cluster_centers_) # 中心值大的那一类是标题# 6. 【结果输出与回溯】
    results = []
    for line, label in zip(all_lines, kmeans.labels_):
        if label == bold_label:
            # 过滤掉伪标题（如 "见；"）if not is_valid_title(line['text']): continue# 【空间回溯】去 doc_orig 找回左边丢失的序号 "1. "
            full_text = recover_prefix(doc_orig[line['page']], line['bbox'], line['text'])
            results.append(full_text)
            
    return results</code></pre>
<br>
<ol>
<li>### 总结与启示</li>
</ol>
<br>
<p>这次经历给我们最大的启示是：<strong>不要被数据的表象（Metadata）所限制，要善用“多模态”思维。</strong></p>
<br>
<p>当文本解析（NLP）走进死胡同时，不妨切换视角，用计算机视觉（CV）去“看”文档。</p>
<br>
<ul>
<li><strong>Metadata 说它是细体，但</strong><strong>像素</strong><strong>说它是粗体，像素不会撒谎。</strong></li>
<li><strong>“先擦除再识别”</strong> 的思路，有效地解决了噪点干扰问题，这种“减法思维”在处理非结构化数据时极其有效。</li>
</ol>
<br>
<p>这套方案最终在我们的项目中实现了 <strong>100% 的提取准确率</strong>，且处理几百页的 PDF 仅需数秒，远超 OCR 方案。</p>
        </article>
    
    </div>
    <footer>
        <p>&copy; 2026 Misaka. Powered by <a href="https://pages.github.com/">GitHub Pages</a></p>
        <p><a href="https://github.com/Misakago">https://github.com/Misakago</a></p>
    </footer>
</body>
</html>
