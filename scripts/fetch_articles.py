#!/usr/bin/env python3
"""
æ–‡ç« å¤„ç†è„šæœ¬
å°† Markdown æ–‡ä»¶ä» posts ç›®å½•å¤åˆ¶åˆ° public/articles ç›®å½•ï¼Œå¹¶ç”Ÿæˆç´¢å¼•æ–‡ä»¶
"""

import os
import re
import json
import shutil
from pathlib import Path
from datetime import datetime
from typing import List, Dict

# é…ç½®
SOURCE_DIR = Path(__file__).parent.parent
POSTS_DIR = SOURCE_DIR / "posts"
OUTPUT_DIR = SOURCE_DIR / "public" / "articles"
IMAGES_OUTPUT_DIR = SOURCE_DIR / "public" / "images"
IMAGES_SOURCE_DIR = SOURCE_DIR / "images"

# è‹±æ–‡ slug æ˜ å°„è¡¨ï¼ˆå…³é”®è¯ -> è‹±æ–‡ slugï¼‰
# é€šè¿‡æ–‡ä»¶åå…³é”®è¯åŒ¹é…ï¼Œé¿å…ä¸­æ–‡å¼•å·é—®é¢˜
SLUG_KEYWORDS = {
    "Keycloak": "keycloak-nonstandard-token-sso-to-oidc-ldap",
    "Paddle": "paddle-ocr-vl-paddlex-local-deployment",
    "SSH": "ssh-dynamic-port-forwarding",
    "Markdownè½¬Word": "markdown-to-word-pipeline",
    "ç«¯å£ä¸å¯ç”¨": "port-unavailability-troubleshooting",
    "ååæ€§èƒ½": "model-throughput-testing-inference-benchmarker",
    "è®¡ç®—æœºè§†è§‰": "cv-extract-fake-bold-titles",
}

# ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)


def get_all_markdown_files() -> List[Path]:
    """è·å–æ‰€æœ‰markdownæ–‡ä»¶ï¼ˆæ’é™¤READMEï¼‰"""
    if not POSTS_DIR.exists():
        print(f"  âš ï¸  æ–‡ç« ç›®å½•ä¸å­˜åœ¨: {POSTS_DIR}")
        return []
    return sorted([
        f for f in POSTS_DIR.glob("*.md")
        if f.name != "README.md"
    ])


def extract_title(content: str, filename: str) -> str:
    """ä»markdownå†…å®¹ä¸­æå–æ ‡é¢˜

    æ”¯æŒä»¥ä¸‹æ ¼å¼:
    - # æ ‡é¢˜
    - 1. # æ ‡é¢˜ (æœ‰åºåˆ—è¡¨åè·Ÿæ ‡é¢˜)
    """
    lines = content.split('\n')

    for line in lines:
        # æ ‡å‡†æ ¼å¼: # æ ‡é¢˜
        match = re.match(r'^#\s+(.+)$', line.strip())
        if match:
            return match.group(1).strip()

        # åˆ—è¡¨æ ¼å¼: 1. # æ ‡é¢˜
        match = re.match(r'^\d+\.\s*#\s+(.+)$', line.strip())
        if match:
            return match.group(1).strip()

    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ ‡é¢˜ï¼Œä½¿ç”¨æ–‡ä»¶å
    return filename.replace('.md', '')


def extract_description(content: str) -> str:
    """æå–æ–‡ç« æè¿°ï¼ˆç¬¬ä¸€æ®µæœ‰æ•ˆå†…å®¹ï¼‰"""
    lines = content.split('\n')

    # è·³è¿‡æ ‡é¢˜è¡Œ
    start_idx = 0
    for i, line in enumerate(lines):
        stripped = line.strip()
        if stripped and not (stripped.startswith('#') or
                            re.match(r'^\d+\.\s*#', stripped)):
            start_idx = i
            break

    # æ‰¾åˆ°ç¬¬ä¸€ä¸ªéç©ºæ®µè½
    for line in lines[start_idx:]:
        stripped = line.strip()
        if stripped and not stripped.startswith('!') and '|' not in stripped:
            # æ¸…ç†markdownè¯­æ³•
            desc = re.sub(r'[*_`\[\]]', '', stripped)
            # ç§»é™¤åˆ—è¡¨æ ‡è®°
            desc = re.sub(r'^[-\*]\s*', '', desc)
            desc = re.sub(r'^\d+\.\s*', '', desc)
            desc = desc.strip()
            if desc:
                return desc[:150] + '...' if len(desc) > 150 else desc

    return ""


def get_file_slug(filename: str) -> str:
    """ä»æ–‡ä»¶åè·å–è‹±æ–‡ slug"""
    # é€šè¿‡å…³é”®è¯åŒ¹é…
    for keyword, slug in SLUG_KEYWORDS.items():
        if keyword in filename:
            return slug

    # å¦‚æœæ²¡æœ‰åŒ¹é…ï¼Œä½¿ç”¨ URL å‹å¥½çš„ä¸­æ–‡
    name = filename.replace('.md', '')
    slug = re.sub(r'[^\w\u4e00-\u9fff\-]', '-', name)
    slug = re.sub(r'-+', '-', slug)
    slug = slug.strip('-')
    return slug


def process_markdown_images(content: str, slug: str) -> str:
    """å¤„ç† Markdown ä¸­çš„å›¾ç‰‡è·¯å¾„

    å°† images/xxx.png è½¬æ¢ä¸º /images/xxx.png
    """
    # æ›¿æ¢å›¾ç‰‡è·¯å¾„
    content = re.sub(
        r'!\[(.*?)\]\(images/([^)]+)\)',
        r'![\1](/images/\2)',
        content
    )
    return content


def copy_images():
    """å¤åˆ¶å›¾ç‰‡åˆ° public ç›®å½•"""
    if not IMAGES_SOURCE_DIR.exists():
        print(f"  â„¹ï¸  å›¾ç‰‡æºç›®å½•ä¸å­˜åœ¨: {IMAGES_SOURCE_DIR}")
        return

    # æ¸…ç†å¹¶é‡å»ºç›®æ ‡ç›®å½•
    if IMAGES_OUTPUT_DIR.exists():
        shutil.rmtree(IMAGES_OUTPUT_DIR)
    IMAGES_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

    # å¤åˆ¶æ‰€æœ‰å›¾ç‰‡
    image_files = list(IMAGES_SOURCE_DIR.glob('*'))
    image_count = 0

    for img in image_files:
        if img.is_file():
            shutil.copy2(img, IMAGES_OUTPUT_DIR / img.name)
            image_count += 1

    print(f"  ğŸ“· å¤åˆ¶äº† {image_count} ä¸ªå›¾ç‰‡æ–‡ä»¶")


def build_articles():
    """æ„å»ºæ–‡ç« ç´¢å¼•å’Œå†…å®¹"""
    print(f"ğŸ”¨ å¼€å§‹å¤„ç†æ–‡ç« ...")

    # æ¸…ç†è¾“å‡ºç›®å½•
    if OUTPUT_DIR.exists():
        for f in OUTPUT_DIR.glob("*.md"):
            f.unlink()
    else:
        OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

    # å¤åˆ¶å›¾ç‰‡
    copy_images()

    # è·å–æ‰€æœ‰markdownæ–‡ä»¶
    md_files = get_all_markdown_files()
    print(f"  ğŸ“ æ‰¾åˆ° {len(md_files)} ç¯‡æ–‡ç« ")

    if not md_files:
        print(f"  âš ï¸  æ²¡æœ‰æ‰¾åˆ°æ–‡ç« æ–‡ä»¶")
        return

    articles = []

    # å¤„ç†æ¯ç¯‡æ–‡ç« 
    for md_file in md_files:
        print(f"    - {md_file.name}")

        # è¯»å–å†…å®¹
        with open(md_file, 'r', encoding='utf-8') as f:
            content = f.read()

        # æå–ä¿¡æ¯
        title = extract_title(content, md_file.name)
        slug = get_file_slug(md_file.name)
        description = extract_description(content)

        # è·å–æ–‡ä»¶ä¿®æ”¹æ—¶é—´ä½œä¸ºå‘å¸ƒæ—¥æœŸ
        mtime = md_file.stat().st_mtime
        date = datetime.fromtimestamp(mtime).strftime('%Y-%m-%d')

        articles.append({
            'title': title,
            'slug': slug,
            'description': description,
            'date': date,
            'filename': md_file.name
        })

        # å¤„ç†å›¾ç‰‡è·¯å¾„
        processed_content = process_markdown_images(content, slug)

        # å†™å…¥å¤„ç†åçš„ markdown æ–‡ä»¶
        output_file = OUTPUT_DIR / f"{slug}.md"
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(processed_content)

    # æŒ‰æ—¥æœŸæ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
    articles.sort(key=lambda x: x['date'], reverse=True)

    # ç”Ÿæˆç´¢å¼•æ–‡ä»¶
    index_file = OUTPUT_DIR / "index.json"
    with open(index_file, 'w', encoding='utf-8') as f:
        json.dump(articles, f, ensure_ascii=False, indent=2)

    print(f"\nâœ… æ–‡ç« å¤„ç†å®Œæˆ!")
    print(f"   - å¤„ç†äº† {len(articles)} ç¯‡æ–‡ç« ")
    print(f"   - è¾“å‡ºç›®å½•: {OUTPUT_DIR}")


if __name__ == '__main__':
    build_articles()
